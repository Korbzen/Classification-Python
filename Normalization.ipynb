{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Für das nächste Beispiel verwenden wir einen Datensatz bei dem Brustkrebs klassifiziert wurde."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importieren eines Datensatzes\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "data = load_breast_cancer()\n",
    "df_data = pd.DataFrame(data.data, columns=data.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target = pd.DataFrame(data['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eine praktische Methode eines dataframes in pandas ist *describe*().\n",
    "\n",
    "Sie zeigt alle Features und ihre statistischen Werte an."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>14.127292</td>\n",
       "      <td>19.289649</td>\n",
       "      <td>91.969033</td>\n",
       "      <td>654.889104</td>\n",
       "      <td>0.096360</td>\n",
       "      <td>0.104341</td>\n",
       "      <td>0.088799</td>\n",
       "      <td>0.048919</td>\n",
       "      <td>0.181162</td>\n",
       "      <td>0.062798</td>\n",
       "      <td>...</td>\n",
       "      <td>16.269190</td>\n",
       "      <td>25.677223</td>\n",
       "      <td>107.261213</td>\n",
       "      <td>880.583128</td>\n",
       "      <td>0.132369</td>\n",
       "      <td>0.254265</td>\n",
       "      <td>0.272188</td>\n",
       "      <td>0.114606</td>\n",
       "      <td>0.290076</td>\n",
       "      <td>0.083946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>3.524049</td>\n",
       "      <td>4.301036</td>\n",
       "      <td>24.298981</td>\n",
       "      <td>351.914129</td>\n",
       "      <td>0.014064</td>\n",
       "      <td>0.052813</td>\n",
       "      <td>0.079720</td>\n",
       "      <td>0.038803</td>\n",
       "      <td>0.027414</td>\n",
       "      <td>0.007060</td>\n",
       "      <td>...</td>\n",
       "      <td>4.833242</td>\n",
       "      <td>6.146258</td>\n",
       "      <td>33.602542</td>\n",
       "      <td>569.356993</td>\n",
       "      <td>0.022832</td>\n",
       "      <td>0.157336</td>\n",
       "      <td>0.208624</td>\n",
       "      <td>0.065732</td>\n",
       "      <td>0.061867</td>\n",
       "      <td>0.018061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>6.981000</td>\n",
       "      <td>9.710000</td>\n",
       "      <td>43.790000</td>\n",
       "      <td>143.500000</td>\n",
       "      <td>0.052630</td>\n",
       "      <td>0.019380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>0.049960</td>\n",
       "      <td>...</td>\n",
       "      <td>7.930000</td>\n",
       "      <td>12.020000</td>\n",
       "      <td>50.410000</td>\n",
       "      <td>185.200000</td>\n",
       "      <td>0.071170</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>0.055040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>11.700000</td>\n",
       "      <td>16.170000</td>\n",
       "      <td>75.170000</td>\n",
       "      <td>420.300000</td>\n",
       "      <td>0.086370</td>\n",
       "      <td>0.064920</td>\n",
       "      <td>0.029560</td>\n",
       "      <td>0.020310</td>\n",
       "      <td>0.161900</td>\n",
       "      <td>0.057700</td>\n",
       "      <td>...</td>\n",
       "      <td>13.010000</td>\n",
       "      <td>21.080000</td>\n",
       "      <td>84.110000</td>\n",
       "      <td>515.300000</td>\n",
       "      <td>0.116600</td>\n",
       "      <td>0.147200</td>\n",
       "      <td>0.114500</td>\n",
       "      <td>0.064930</td>\n",
       "      <td>0.250400</td>\n",
       "      <td>0.071460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>13.370000</td>\n",
       "      <td>18.840000</td>\n",
       "      <td>86.240000</td>\n",
       "      <td>551.100000</td>\n",
       "      <td>0.095870</td>\n",
       "      <td>0.092630</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.179200</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>...</td>\n",
       "      <td>14.970000</td>\n",
       "      <td>25.410000</td>\n",
       "      <td>97.660000</td>\n",
       "      <td>686.500000</td>\n",
       "      <td>0.131300</td>\n",
       "      <td>0.211900</td>\n",
       "      <td>0.226700</td>\n",
       "      <td>0.099930</td>\n",
       "      <td>0.282200</td>\n",
       "      <td>0.080040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>15.780000</td>\n",
       "      <td>21.800000</td>\n",
       "      <td>104.100000</td>\n",
       "      <td>782.700000</td>\n",
       "      <td>0.105300</td>\n",
       "      <td>0.130400</td>\n",
       "      <td>0.130700</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>0.195700</td>\n",
       "      <td>0.066120</td>\n",
       "      <td>...</td>\n",
       "      <td>18.790000</td>\n",
       "      <td>29.720000</td>\n",
       "      <td>125.400000</td>\n",
       "      <td>1084.000000</td>\n",
       "      <td>0.146000</td>\n",
       "      <td>0.339100</td>\n",
       "      <td>0.382900</td>\n",
       "      <td>0.161400</td>\n",
       "      <td>0.317900</td>\n",
       "      <td>0.092080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>28.110000</td>\n",
       "      <td>39.280000</td>\n",
       "      <td>188.500000</td>\n",
       "      <td>2501.000000</td>\n",
       "      <td>0.163400</td>\n",
       "      <td>0.345400</td>\n",
       "      <td>0.426800</td>\n",
       "      <td>0.201200</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>0.097440</td>\n",
       "      <td>...</td>\n",
       "      <td>36.040000</td>\n",
       "      <td>49.540000</td>\n",
       "      <td>251.200000</td>\n",
       "      <td>4254.000000</td>\n",
       "      <td>0.222600</td>\n",
       "      <td>1.058000</td>\n",
       "      <td>1.252000</td>\n",
       "      <td>0.291000</td>\n",
       "      <td>0.663800</td>\n",
       "      <td>0.207500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       mean radius  mean texture  mean perimeter    mean area  \\\n",
       "count   569.000000    569.000000      569.000000   569.000000   \n",
       "mean     14.127292     19.289649       91.969033   654.889104   \n",
       "std       3.524049      4.301036       24.298981   351.914129   \n",
       "min       6.981000      9.710000       43.790000   143.500000   \n",
       "25%      11.700000     16.170000       75.170000   420.300000   \n",
       "50%      13.370000     18.840000       86.240000   551.100000   \n",
       "75%      15.780000     21.800000      104.100000   782.700000   \n",
       "max      28.110000     39.280000      188.500000  2501.000000   \n",
       "\n",
       "       mean smoothness  mean compactness  mean concavity  mean concave points  \\\n",
       "count       569.000000        569.000000      569.000000           569.000000   \n",
       "mean          0.096360          0.104341        0.088799             0.048919   \n",
       "std           0.014064          0.052813        0.079720             0.038803   \n",
       "min           0.052630          0.019380        0.000000             0.000000   \n",
       "25%           0.086370          0.064920        0.029560             0.020310   \n",
       "50%           0.095870          0.092630        0.061540             0.033500   \n",
       "75%           0.105300          0.130400        0.130700             0.074000   \n",
       "max           0.163400          0.345400        0.426800             0.201200   \n",
       "\n",
       "       mean symmetry  mean fractal dimension  ...  worst radius  \\\n",
       "count     569.000000              569.000000  ...    569.000000   \n",
       "mean        0.181162                0.062798  ...     16.269190   \n",
       "std         0.027414                0.007060  ...      4.833242   \n",
       "min         0.106000                0.049960  ...      7.930000   \n",
       "25%         0.161900                0.057700  ...     13.010000   \n",
       "50%         0.179200                0.061540  ...     14.970000   \n",
       "75%         0.195700                0.066120  ...     18.790000   \n",
       "max         0.304000                0.097440  ...     36.040000   \n",
       "\n",
       "       worst texture  worst perimeter   worst area  worst smoothness  \\\n",
       "count     569.000000       569.000000   569.000000        569.000000   \n",
       "mean       25.677223       107.261213   880.583128          0.132369   \n",
       "std         6.146258        33.602542   569.356993          0.022832   \n",
       "min        12.020000        50.410000   185.200000          0.071170   \n",
       "25%        21.080000        84.110000   515.300000          0.116600   \n",
       "50%        25.410000        97.660000   686.500000          0.131300   \n",
       "75%        29.720000       125.400000  1084.000000          0.146000   \n",
       "max        49.540000       251.200000  4254.000000          0.222600   \n",
       "\n",
       "       worst compactness  worst concavity  worst concave points  \\\n",
       "count         569.000000       569.000000            569.000000   \n",
       "mean            0.254265         0.272188              0.114606   \n",
       "std             0.157336         0.208624              0.065732   \n",
       "min             0.027290         0.000000              0.000000   \n",
       "25%             0.147200         0.114500              0.064930   \n",
       "50%             0.211900         0.226700              0.099930   \n",
       "75%             0.339100         0.382900              0.161400   \n",
       "max             1.058000         1.252000              0.291000   \n",
       "\n",
       "       worst symmetry  worst fractal dimension  \n",
       "count      569.000000               569.000000  \n",
       "mean         0.290076                 0.083946  \n",
       "std          0.061867                 0.018061  \n",
       "min          0.156500                 0.055040  \n",
       "25%          0.250400                 0.071460  \n",
       "50%          0.282200                 0.080040  \n",
       "75%          0.317900                 0.092080  \n",
       "max          0.663800                 0.207500  \n",
       "\n",
       "[8 rows x 30 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aufteilen des Datensatzes in test & training set\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(df_data, df_target, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf = SVC(gamma='scale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Korbinian\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 50,  17],\n",
       "       [  1, 120]], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(Y_test, prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Was bedeutet der Output nun für uns?\n",
    "\n",
    "Auf der linken Achse der Matrix stehen die realen Werte und auf der oberen die vorhergesagten.\n",
    "\n",
    "Unser Klassifizierer klassifiziert also:\n",
    "- 54 von 74 Leute ohne Brustkrebs richtig\n",
    "- 112 von 114 Leute mit Brustkrebs richtig\n",
    "    \n",
    "Das bedeutet, dass 20 Leute ohne Brustkrebs als krank(False Positive) und 2 Leute mit Brustkrebs als gesund(False Negative) klassifiziert."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wie können wir unser Modell nun verbessern?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es gibt mehrere Wege ein Machine Learning Model zu verbessern. Neben einem anderen Algorithmus gibt es vor allem im Preprocessing Wege es zu verbessern.\n",
    "- Feature Engineering: dabei wählt man bestimmte Features aus und versucht anhand von Metriken (z.B. Abhängigkeit der Variablen) das Ergebnis zu verbessern\n",
    "- Dimensionality Reduction: dabei wird der gesamte Feature Raum auf einen Unterraum abgebildet (Ein Beispiel hierfür ist PCA)\n",
    "- Normalisieren: Alle Variablen auf den gleichen Werteraum normalisieren\n",
    "- Hyperparameter optimieren\n",
    "\n",
    "Wir werden uns im nächsten Abschnitt mit den letzteren drei Möglichkeiten beschäftigen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zunächst importieren wir wieder die notwendigen Pakete\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zunächst normalisieren wir alle Werte in unserem Datensatz auf einen Abschnitt zwischen 0 & 1.\n",
    "\n",
    "Dadurch kann der Algorithmus besser konvergieren, da der Fehler nicht so schnell ansteigt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_scaled = MinMaxScaler().fit_transform(df_data)\n",
    "# the output from scikit-learn methods are numpy arrays so we need to transform it into a dataframe\n",
    "df_data_scaled = pd.DataFrame(data_scaled)\n",
    "df_data_scaled.columns = df_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>0.338222</td>\n",
       "      <td>0.323965</td>\n",
       "      <td>0.332935</td>\n",
       "      <td>0.216920</td>\n",
       "      <td>0.394785</td>\n",
       "      <td>0.260601</td>\n",
       "      <td>0.208058</td>\n",
       "      <td>0.243137</td>\n",
       "      <td>0.379605</td>\n",
       "      <td>0.270379</td>\n",
       "      <td>...</td>\n",
       "      <td>0.296663</td>\n",
       "      <td>0.363998</td>\n",
       "      <td>0.283138</td>\n",
       "      <td>0.170906</td>\n",
       "      <td>0.404138</td>\n",
       "      <td>0.220212</td>\n",
       "      <td>0.217403</td>\n",
       "      <td>0.393836</td>\n",
       "      <td>0.263307</td>\n",
       "      <td>0.189596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.166787</td>\n",
       "      <td>0.145453</td>\n",
       "      <td>0.167915</td>\n",
       "      <td>0.149274</td>\n",
       "      <td>0.126967</td>\n",
       "      <td>0.161992</td>\n",
       "      <td>0.186785</td>\n",
       "      <td>0.192857</td>\n",
       "      <td>0.138456</td>\n",
       "      <td>0.148702</td>\n",
       "      <td>...</td>\n",
       "      <td>0.171940</td>\n",
       "      <td>0.163813</td>\n",
       "      <td>0.167352</td>\n",
       "      <td>0.139932</td>\n",
       "      <td>0.150779</td>\n",
       "      <td>0.152649</td>\n",
       "      <td>0.166633</td>\n",
       "      <td>0.225884</td>\n",
       "      <td>0.121954</td>\n",
       "      <td>0.118466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>0.223342</td>\n",
       "      <td>0.218465</td>\n",
       "      <td>0.216847</td>\n",
       "      <td>0.117413</td>\n",
       "      <td>0.304595</td>\n",
       "      <td>0.139685</td>\n",
       "      <td>0.069260</td>\n",
       "      <td>0.100944</td>\n",
       "      <td>0.282323</td>\n",
       "      <td>0.163016</td>\n",
       "      <td>...</td>\n",
       "      <td>0.180719</td>\n",
       "      <td>0.241471</td>\n",
       "      <td>0.167837</td>\n",
       "      <td>0.081130</td>\n",
       "      <td>0.300007</td>\n",
       "      <td>0.116337</td>\n",
       "      <td>0.091454</td>\n",
       "      <td>0.223127</td>\n",
       "      <td>0.185098</td>\n",
       "      <td>0.107700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>0.302381</td>\n",
       "      <td>0.308759</td>\n",
       "      <td>0.293345</td>\n",
       "      <td>0.172895</td>\n",
       "      <td>0.390358</td>\n",
       "      <td>0.224679</td>\n",
       "      <td>0.144189</td>\n",
       "      <td>0.166501</td>\n",
       "      <td>0.369697</td>\n",
       "      <td>0.243892</td>\n",
       "      <td>...</td>\n",
       "      <td>0.250445</td>\n",
       "      <td>0.356876</td>\n",
       "      <td>0.235320</td>\n",
       "      <td>0.123206</td>\n",
       "      <td>0.397081</td>\n",
       "      <td>0.179110</td>\n",
       "      <td>0.181070</td>\n",
       "      <td>0.343402</td>\n",
       "      <td>0.247782</td>\n",
       "      <td>0.163977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>0.416442</td>\n",
       "      <td>0.408860</td>\n",
       "      <td>0.416765</td>\n",
       "      <td>0.271135</td>\n",
       "      <td>0.475490</td>\n",
       "      <td>0.340531</td>\n",
       "      <td>0.306232</td>\n",
       "      <td>0.367793</td>\n",
       "      <td>0.453030</td>\n",
       "      <td>0.340354</td>\n",
       "      <td>...</td>\n",
       "      <td>0.386339</td>\n",
       "      <td>0.471748</td>\n",
       "      <td>0.373475</td>\n",
       "      <td>0.220901</td>\n",
       "      <td>0.494156</td>\n",
       "      <td>0.302520</td>\n",
       "      <td>0.305831</td>\n",
       "      <td>0.554639</td>\n",
       "      <td>0.318155</td>\n",
       "      <td>0.242949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       mean radius  mean texture  mean perimeter   mean area  mean smoothness  \\\n",
       "count   569.000000    569.000000      569.000000  569.000000       569.000000   \n",
       "mean      0.338222      0.323965        0.332935    0.216920         0.394785   \n",
       "std       0.166787      0.145453        0.167915    0.149274         0.126967   \n",
       "min       0.000000      0.000000        0.000000    0.000000         0.000000   \n",
       "25%       0.223342      0.218465        0.216847    0.117413         0.304595   \n",
       "50%       0.302381      0.308759        0.293345    0.172895         0.390358   \n",
       "75%       0.416442      0.408860        0.416765    0.271135         0.475490   \n",
       "max       1.000000      1.000000        1.000000    1.000000         1.000000   \n",
       "\n",
       "       mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "count        569.000000      569.000000           569.000000     569.000000   \n",
       "mean           0.260601        0.208058             0.243137       0.379605   \n",
       "std            0.161992        0.186785             0.192857       0.138456   \n",
       "min            0.000000        0.000000             0.000000       0.000000   \n",
       "25%            0.139685        0.069260             0.100944       0.282323   \n",
       "50%            0.224679        0.144189             0.166501       0.369697   \n",
       "75%            0.340531        0.306232             0.367793       0.453030   \n",
       "max            1.000000        1.000000             1.000000       1.000000   \n",
       "\n",
       "       mean fractal dimension  ...  worst radius  worst texture  \\\n",
       "count              569.000000  ...    569.000000     569.000000   \n",
       "mean                 0.270379  ...      0.296663       0.363998   \n",
       "std                  0.148702  ...      0.171940       0.163813   \n",
       "min                  0.000000  ...      0.000000       0.000000   \n",
       "25%                  0.163016  ...      0.180719       0.241471   \n",
       "50%                  0.243892  ...      0.250445       0.356876   \n",
       "75%                  0.340354  ...      0.386339       0.471748   \n",
       "max                  1.000000  ...      1.000000       1.000000   \n",
       "\n",
       "       worst perimeter  worst area  worst smoothness  worst compactness  \\\n",
       "count       569.000000  569.000000        569.000000         569.000000   \n",
       "mean          0.283138    0.170906          0.404138           0.220212   \n",
       "std           0.167352    0.139932          0.150779           0.152649   \n",
       "min           0.000000    0.000000          0.000000           0.000000   \n",
       "25%           0.167837    0.081130          0.300007           0.116337   \n",
       "50%           0.235320    0.123206          0.397081           0.179110   \n",
       "75%           0.373475    0.220901          0.494156           0.302520   \n",
       "max           1.000000    1.000000          1.000000           1.000000   \n",
       "\n",
       "       worst concavity  worst concave points  worst symmetry  \\\n",
       "count       569.000000            569.000000      569.000000   \n",
       "mean          0.217403              0.393836        0.263307   \n",
       "std           0.166633              0.225884        0.121954   \n",
       "min           0.000000              0.000000        0.000000   \n",
       "25%           0.091454              0.223127        0.185098   \n",
       "50%           0.181070              0.343402        0.247782   \n",
       "75%           0.305831              0.554639        0.318155   \n",
       "max           1.000000              1.000000        1.000000   \n",
       "\n",
       "       worst fractal dimension  \n",
       "count               569.000000  \n",
       "mean                  0.189596  \n",
       "std                   0.118466  \n",
       "min                   0.000000  \n",
       "25%                   0.107700  \n",
       "50%                   0.163977  \n",
       "75%                   0.242949  \n",
       "max                   1.000000  \n",
       "\n",
       "[8 rows x 30 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data_scaled.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun sind alle unsere Werte auf den Bereich 0...1 normalisiert.\n",
    "Versuchen wir jetzt noch einmal das selbe Modell zu trainieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Korbinian\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 63,   5],\n",
       "       [  2, 118]], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2 = SVC(gamma='scale')\n",
    "# Split the datasets again\n",
    "X_train2, X_test2, Y_train2, Y_test2 = train_test_split(df_data_scaled, df_target, test_size=0.33)\n",
    "clf2.fit(X_train2, Y_train2)\n",
    "prediction2 = clf2.predict(X_test2)\n",
    "\n",
    "confusion_matrix(Y_test2, prediction2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie wir sehen ist unsere Anzahl an False Positives sehr stark gesunken.\n",
    "\n",
    "Das liegt daran, dass unsere Werte nun alle die gleiche Wertigkeit haben.\n",
    "\n",
    "Bildlich bedeutet das, dass eine Messung die zwischen 0...1 liegt nun die gleiche Gewichtung hat, wie -100...100.\n",
    "\n",
    "## Hyperparameter optimieren\n",
    "Machine Learning Algorithmen haben, wie wir schon mit der Lernrate beim Perceptron gesehen haben Hyperparameter.\n",
    "\n",
    "Diese können wir nutzen um unseren Algorithmus zu verbessern.\n",
    "\n",
    "Die Attribute der SVC Klasse findet man unter: \n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Korbinian\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 63,   5],\n",
       "       [  2, 118]], dtype=int64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ein Beispiel\n",
    "\n",
    "clf3 = SVC(gamma='scale', degree=4)\n",
    "# Split the datasets again\n",
    "clf3.fit(X_train2, Y_train2)\n",
    "prediction3 = clf3.predict(X_test2)\n",
    "\n",
    "confusion_matrix(Y_test2, prediction3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Dimensionsreduktion\n",
    "Nun nutzen wir Principal Component Analysis. Der Algorithmus sucht eine Funktion die Varianz des Datensatzes mit der so wenig Variablen wie möglich abzubilden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=10)\n",
    "data_reduced = pca.fit_transform(df_data_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of             0         1         2         3         4         5         6  \\\n",
       "0    1.387021  0.426895 -0.541703  0.048483 -0.072198  0.190817  0.236314   \n",
       "1    0.462308 -0.556947 -0.205175 -0.042830  0.016111  0.015604  0.043139   \n",
       "2    0.954621 -0.109701 -0.147848 -0.001068 -0.033798  0.069062 -0.108166   \n",
       "3    1.000816  1.525089 -0.053271 -0.207916 -0.219381  0.388007  0.194518   \n",
       "4    0.626828 -0.302471 -0.409336  0.238811 -0.002192 -0.157212 -0.063308   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "564  1.002840 -0.474785 -0.100041  0.272995 -0.083888 -0.309121 -0.129458   \n",
       "565  0.620757 -0.517200  0.400360  0.182443 -0.092984 -0.046000 -0.083334   \n",
       "566  0.226311 -0.287946  0.315224 -0.011747  0.218517 -0.080005 -0.030991   \n",
       "567  1.677834  0.335946  0.296116 -0.156305  0.070204  0.109057  0.068627   \n",
       "568 -0.905068 -0.104109  0.382860  0.068361  0.072986  0.196660  0.125678   \n",
       "\n",
       "            7         8         9  \n",
       "0   -0.039454  0.077588  0.155296  \n",
       "1    0.020643 -0.070639 -0.085285  \n",
       "2    0.007362 -0.059335 -0.073687  \n",
       "3    0.143497  0.176997 -0.140950  \n",
       "4    0.045931  0.002423  0.000544  \n",
       "..        ...       ...       ...  \n",
       "564  0.006006 -0.110996  0.090695  \n",
       "565 -0.111682  0.039792  0.014458  \n",
       "566  0.015708 -0.108336 -0.076912  \n",
       "567 -0.092474  0.083793  0.005444  \n",
       "568  0.039432 -0.019867  0.105470  \n",
       "\n",
       "[569 rows x 10 columns]>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data_reduced = pd.DataFrame(data_reduced)\n",
    "df_data_reduced.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "var_exp =  pca.explained_variance_ratio_\n",
    "cum_var_exp = np.cumsum(var_exp)\n",
    "\n",
    "plt.bar(range(1,11), var_exp, alpha=0.5, align='center',\n",
    "        label='individual explained variance')\n",
    "plt.step(range(1,11), cum_var_exp, where='mid',\n",
    "         label='cumulative explained variance')\n",
    "plt.ylabel('Explained variance ratio')\n",
    "plt.xlabel('Principal components')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie wir sehen können beschreiben die ersten 5 Dimensionen u\"ber 90% der Varianz im Datensatz (also auch des Informationsgehalts)\n",
    "Wir können also die PCA auf lediglich 5 Komponenten reduzieren lassen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=3)\n",
    "data_reduced = pca.fit_transform(df_data_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Korbinian\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 64,   5],\n",
       "       [  0, 119]], dtype=int64)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_reduced = SVC(gamma='scale')\n",
    "# Split the datasets again\n",
    "X_train3, X_test3, Y_train3, Y_test3 = train_test_split(df_data_reduced, df_target, test_size=0.33)\n",
    "clf_reduced.fit(X_train3, Y_train3)\n",
    "prediction_red = clf_reduced.predict(X_test3)\n",
    "\n",
    "confusion_matrix(Y_test3, prediction_red)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
